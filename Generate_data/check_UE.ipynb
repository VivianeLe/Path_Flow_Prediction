{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_file(filename):\n",
    "  with open(filename, \"rb\") as file:\n",
    "      stat = pickle.load(file)\n",
    "      file.close()\n",
    "  return stat\n",
    "\n",
    "def get_origin_path(stat):\n",
    "    path_link = stat['data']['paths_link']\n",
    "    od = [k for k in path_link.keys()]\n",
    "    path1 = [tuple(p[0]) for p in path_link.values()]\n",
    "    path2 = [tuple(p[1]) for p in path_link.values()]\n",
    "    path3 = [tuple(p[2]) for p in path_link.values()]\n",
    "\n",
    "    demand_dic = stat[\"data\"][\"demand\"]\n",
    "    demand = [v for v in demand_dic.values()]\n",
    "    path_link_df = pd.DataFrame({\"od\": od, \"demand\":demand, \"path1\": path1, \"path2\": path2, \"path3\": path3})\n",
    "    return path_link_df\n",
    "\n",
    "def get_UE_link_cost(stat):\n",
    "    # return a dataframe of link cost, link flow\n",
    "    link = stat['data']['network'].copy()\n",
    "    link['link_flow'] = stat['link_flow']\n",
    "    # Calculate link cost\n",
    "    link['link_cost'] = round(link['free_flow_time']*\\\n",
    "                            (1+link['b']*((link['link_flow']/link['capacity'])**1)), 2)\n",
    "    return link\n",
    "\n",
    "# Calculate path travel time for each od pair\n",
    "def calculate_path_cost(row, link_df):\n",
    "    sum_time = 0\n",
    "    for l in row:\n",
    "        sum_time += link_df.at[l, 'link_cost']\n",
    "    return round(sum_time, 2)\n",
    "\n",
    "# calculate each link flow based on path flow\n",
    "def extract_link_flow(path_link, flows):\n",
    "    # input: a dictionary of {od pair: path_link} and list of flow distribution\n",
    "    # return a dictionary of link flow\n",
    "    path_flow = {}\n",
    "    for path_set, flow_set in zip(path_link.values(), flows):\n",
    "        for path, flow in zip(path_set, flow_set):\n",
    "            path_flow[tuple(path)] = flow\n",
    "\n",
    "    aggregated_sums = defaultdict(float)\n",
    "    for path, flow in path_flow.items():\n",
    "        for link in path:\n",
    "            aggregated_sums[link] += flow\n",
    "    link_flow = dict(aggregated_sums)\n",
    "    return link_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>od</th>\n",
       "      <th>demand</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "      <th>path1_cost</th>\n",
       "      <th>path2_cost</th>\n",
       "      <th>path3_cost</th>\n",
       "      <th>flow1</th>\n",
       "      <th>flow2</th>\n",
       "      <th>flow3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(6, 22)</td>\n",
       "      <td>1878</td>\n",
       "      <td>(18, 24, 42, 60)</td>\n",
       "      <td>(20, 36, 42, 60)</td>\n",
       "      <td>(20, 38, 54, 60)</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(23, 24)</td>\n",
       "      <td>976</td>\n",
       "      <td>(76,)</td>\n",
       "      <td>(65, 62, 68)</td>\n",
       "      <td>(75, 61, 58, 62, 68)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.66</td>\n",
       "      <td>976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 24)</td>\n",
       "      <td>614</td>\n",
       "      <td>(0, 4, 8, 14, 32, 50, 68)</td>\n",
       "      <td>(2, 18, 22, 26, 32, 50, 68)</td>\n",
       "      <td>(0, 6, 22, 26, 32, 50, 68)</td>\n",
       "      <td>7.18</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(6, 12)</td>\n",
       "      <td>871</td>\n",
       "      <td>(18, 24)</td>\n",
       "      <td>(20, 36)</td>\n",
       "      <td>(18, 22, 28, 41)</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.98</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>1478</td>\n",
       "      <td>(0, 4, 8)</td>\n",
       "      <td>(2, 18, 7, 4, 8)</td>\n",
       "      <td>(0, 6, 22, 11, 8)</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.96</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         od  demand                      path1                        path2  \\\n",
       "0   (6, 22)    1878           (18, 24, 42, 60)             (20, 36, 42, 60)   \n",
       "1  (23, 24)     976                      (76,)                 (65, 62, 68)   \n",
       "2   (1, 24)     614  (0, 4, 8, 14, 32, 50, 68)  (2, 18, 22, 26, 32, 50, 68)   \n",
       "3   (6, 12)     871                   (18, 24)                     (20, 36)   \n",
       "4    (1, 4)    1478                  (0, 4, 8)             (2, 18, 7, 4, 8)   \n",
       "\n",
       "                        path3  path1_cost  path2_cost  path3_cost  flow1  \\\n",
       "0            (20, 38, 54, 60)        4.05        4.05        4.03      0   \n",
       "1        (75, 61, 58, 62, 68)        1.00        2.88        4.66    976   \n",
       "2  (0, 6, 22, 26, 32, 50, 68)        7.18        6.98        7.07      0   \n",
       "3            (18, 22, 28, 41)        1.97        1.97        3.98      0   \n",
       "4           (0, 6, 22, 11, 8)        3.38        4.96        5.05   1478   \n",
       "\n",
       "   flow2  flow3  \n",
       "0      0   1878  \n",
       "1      0      0  \n",
       "2    614      0  \n",
       "3    871      0  \n",
       "4      0      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check UE of origin dataset \n",
    "filename = '../Output/5by5_Data1800'\n",
    "stat = read_file(filename)\n",
    "path_link_df = get_origin_path(stat)\n",
    "UE_link = get_UE_link_cost(stat)\n",
    "\n",
    "path_link_df['path1_cost'] = path_link_df['path1'].apply(lambda x: calculate_path_cost(x, UE_link))\n",
    "path_link_df['path2_cost'] = path_link_df['path2'].apply(lambda x: calculate_path_cost(x, UE_link))\n",
    "path_link_df['path3_cost'] = path_link_df['path3'].apply(lambda x: calculate_path_cost(x, UE_link))\n",
    "\n",
    "flows = stat['path_flow']\n",
    "path_link_df['flow1'] = [f[0] for f in flows]\n",
    "path_link_df['flow2'] = [f[1] for f in flows]\n",
    "path_link_df['flow3'] = [f[2] for f in flows]\n",
    "\n",
    "path_link_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def load_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = np.loadtxt(f)\n",
    "    num_tensors = data.size // (3 * 625)\n",
    "    reshaped_data = data.reshape((num_tensors, 3, 625))\n",
    "    tensors = [tf.convert_to_tensor(reshaped_data[i], dtype=tf.float32) for i in range(num_tensors)]\n",
    "    return tensors\n",
    "\n",
    "predicted_values = load_from_file('../predicted_values.txt')\n",
    "print(len(predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow(tensor):\n",
    "  # input: a single tensor of predicted path flow\n",
    "  # return a dataframe of full information: od pair, demand, path set, predicted path flow\n",
    "  final_dict = {}\n",
    "  for sub_flow_index, sub_flow in enumerate(tensor):\n",
    "    sub_flow_dict = {(i+1, j+1): int(sub_flow[i, j]) for i in range(sub_flow.shape[0]) for j in range(sub_flow.shape[1])}\n",
    "\n",
    "    for key, value in sub_flow_dict.items():\n",
    "        if key not in final_dict:\n",
    "            final_dict[key] = [None] * tensor.shape[0]\n",
    "        final_dict[key][sub_flow_index] = value\n",
    "  final_dict = {k: v for k, v in final_dict.items() if not all(val == 0 for val in v)}\n",
    "  return final_dict\n",
    "\n",
    "def create_pred_df(tensor, stat):\n",
    "  final_dict = extract_flow(tensor)\n",
    "  print(\"Number of OD pairs predicted: \", len(final_dict))\n",
    "  print(\"Number of origin OD pairs: \", len(stat['path_flow']))\n",
    "  \n",
    "  flow_df = pd.DataFrame.from_dict(final_dict, orient='index', columns=['pred_f1', 'pred_f2', 'pred_f3']).reset_index()\n",
    "  flow_df.rename(columns={'index': 'od'}, inplace=True)\n",
    "  pred_df = get_origin_path(stat)[['od', 'demand', 'path1', 'path2', 'path3']]\n",
    "  pred_df = pd.merge(pred_df, flow_df, how='left', on='od')\n",
    "  nan_val = pred_df['pred_f1'].isna().sum()\n",
    "  # Percentage of nan value\n",
    "  print(\"Nan values: \", nan_val, \" -- \", round(nan_val/len(stat['path_flow'])*100,2), \"%\")\n",
    "  pred_df = pred_df.fillna(0)\n",
    "  return pred_df\n",
    "\n",
    "# Calculate link flow from pred path flow\n",
    "def sum_pred_link_flow(pred_df, stat):\n",
    "    pred_path_flow = pred_df[['pred_f1', 'pred_f2', 'pred_f3']].values.tolist()\n",
    "    path_link = stat['data']['paths_link']\n",
    "\n",
    "    pred_link_flow = extract_link_flow(path_link, pred_path_flow)\n",
    "    pred_link_flow = pd.DataFrame.from_dict(pred_link_flow, orient='index', columns=['pred_link_flow']).sort_index(ascending=True).reset_index()\n",
    "    pred_link_flow.rename(columns={'index': 'link_id'}, inplace=True)\n",
    "    link = stat['data']['network'].copy()[['link_id', 'capacity', 'free_flow_time', 'b']]\n",
    "    output = pd.merge(link, pred_link_flow, how='left', on='link_id')\n",
    "    output = output.fillna(0)\n",
    "    output['link_cost'] = round(output['free_flow_time']*\\\n",
    "                            (1+output['b']*((output['pred_link_flow']/output['capacity'])**1)), 2)\n",
    "    return output\n",
    "\n",
    "def calculate_delay(pred_df, pred_link_flow):\n",
    "    pred_df['path1_cost'] = pred_df['path1'].apply(lambda x: calculate_path_cost(x, pred_link_flow))\n",
    "    pred_df['path2_cost'] = pred_df['path2'].apply(lambda x: calculate_path_cost(x, pred_link_flow))\n",
    "    pred_df['path3_cost'] = pred_df['path3'].apply(lambda x: calculate_path_cost(x, pred_link_flow))\n",
    "    pred_df['min_path_cost'] = pred_df[['path1_cost', 'path2_cost', 'path3_cost']].min(axis=1)\n",
    "    pred_df['delay'] = (\n",
    "        pred_df['pred_f1'] * (pred_df['path1_cost'] - pred_df['min_path_cost']) +\n",
    "        pred_df['pred_f2'] * (pred_df['path2_cost'] - pred_df['min_path_cost']) +\n",
    "        pred_df['pred_f3'] * (pred_df['path3_cost'] - pred_df['min_path_cost'])\n",
    "    )\n",
    "    avg_delay = pred_df['delay'].sum()/pred_df['demand'].sum()\n",
    "    #return average delay in minutes\n",
    "    return avg_delay*60\n",
    "\n",
    "def single_avg_delay(pred_tensor, filename):\n",
    "    stat = read_file(filename)\n",
    "    a = tf.reshape(pred_tensor, (3, 25, 25))\n",
    "    pred_df = create_pred_df(a, stat)\n",
    "    pred_link_flow = sum_pred_link_flow(pred_df, stat)\n",
    "    avg_delay = calculate_delay(pred_df, pred_link_flow)\n",
    "    return avg_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../parameters.py\n",
    "p = Params()\n",
    "\n",
    "# Check number of OD pair in origin dataset \n",
    "start_from=1800\n",
    "files = []\n",
    "for i in range(10):\n",
    "    file_name = ''.join([p.base_path, str(start_from+i)])\n",
    "    files.append(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OD pairs predicted:  322\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  54  --  42.52 %\n",
      "Average delay: 3.817 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  317\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  54  --  42.52 %\n",
      "Average delay: 4.133 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  311\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  51  --  40.16 %\n",
      "Average delay: 1.65 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  315\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  54  --  42.52 %\n",
      "Average delay: 3.999 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  318\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  58  --  45.67 %\n",
      "Average delay: 3.455 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  317\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  60  --  47.24 %\n",
      "Average delay: 3.42 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  322\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  43  --  33.86 %\n",
      "Average delay: 6.932 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  313\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  49  --  38.58 %\n",
      "Average delay: 1.992 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  313\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  61  --  48.03 %\n",
      "Average delay: 5.084 mins\n",
      "-----------------------------\n",
      "Number of OD pairs predicted:  312\n",
      "Number of origin OD pairs:  127\n",
      "Nan values:  60  --  47.24 %\n",
      "Average delay: 1.74 mins\n",
      "-----------------------------\n",
      "avg delay of prediction:  3.6222227651639507\n"
     ]
    }
   ],
   "source": [
    "# Check len of predicted path flow distribution\n",
    "filename = '../Output/5by5_Data1800'\n",
    "\n",
    "sum_delay = 0\n",
    "for i, filename in zip(predicted_values, files):\n",
    "    avg_delay = single_avg_delay(i, filename)\n",
    "    sum_delay += avg_delay\n",
    "    print(f\"Average delay: {round(avg_delay,3)} mins\")\n",
    "    print(\"-----------------------------\")\n",
    "print(\"avg delay of prediction: \", sum_delay/len(predicted_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
