{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD SOLUTION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from attention import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.58.1-cp38-cp38-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in c:\\users\\le\\anaconda\\envs\\viviane-gpu\\lib\\site-packages (from numba) (1.24.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\le\\anaconda\\envs\\viviane-gpu\\lib\\site-packages (from numba) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\le\\anaconda\\envs\\viviane-gpu\\lib\\site-packages (from importlib-metadata->numba) (3.17.0)\n",
      "Downloading numba-0.58.1-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB 435.7 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/2.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.6 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.0/2.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.41.1-cp38-cp38-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/28.1 MB 16.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.1/28.1 MB 11.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/28.1 MB 12.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.3/28.1 MB 12.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 12.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.4/28.1 MB 11.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 4.1/28.1 MB 11.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.7/28.1 MB 11.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 5.3/28.1 MB 11.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.8/28.1 MB 12.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.6/28.1 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/28.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.6/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.2/28.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.8/28.1 MB 12.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.4/28.1 MB 12.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.0/28.1 MB 11.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.6/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.2/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.8/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.2/28.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.7/28.1 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 13.3/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.9/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.5/28.1 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 15.1/28.1 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.7/28.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.3/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.9/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.5/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.1/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.5/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.1/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.7/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 20.2/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.8/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.4/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 22.0/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.6/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.2/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.7/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.0/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.6/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.2/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.8/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.4/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.9/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract OD demand and path set (X and Y)\n",
    "X: OD demand, graph (link feature), path, link-path adj \\\n",
    "Y: path flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py\n",
    "%run attention.py\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, size, input_dim0, input_dim1, output_dim0, output_dim1, standard_norm, start_from=0):\n",
    "        super().__init__()\n",
    "        self.path_encoded = path_encoder() # Get path encode dictionary\n",
    "        self.entries = size\n",
    "        self.X = torch.zeros([size, input_dim0, input_dim1], dtype=torch.float32)\n",
    "        self.Y = torch.zeros([size, output_dim0, output_dim1], dtype=torch.float32)\n",
    "\n",
    "        for i in tqdm(range(size)) :\n",
    "            file_name = f\"Output/5by5_Data{start_from+i}\"\n",
    "            x, y = generate_xy(file_name, self.path_encoded, standard_norm)\n",
    "            self.X[i] = x\n",
    "            self.Y[i] = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.entries\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.X[idx]\n",
    "        data_label = self.Y[idx]\n",
    "        return data_point, data_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907cf249229148069d34e9711d469b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %run helpers.py\n",
    "sequence_leng = 625\n",
    "input_dim = 9\n",
    "output_dim = 3\n",
    "batch_size = 32\n",
    "train_size = 1000\n",
    "val_size = 500\n",
    "standard_norm = 'standardize'\n",
    "\n",
    "train_dataset = Dataset(train_size, sequence_leng, input_dim, sequence_leng, output_dim, standard_norm)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13203a8861ab4593b3e8d715ce56ceac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standard_norm = 'normalize'\n",
    "val_dataset = Dataset(val_size, sequence_leng, input_dim, sequence_leng, output_dim, standard_norm, start_from=train_size)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1533541c05c647afaddd87ec5dbb38af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(torch.cuda.is_available())\n",
    "%run helpers.py\n",
    "\n",
    "path_encoded = path_encoder()\n",
    "X = torch.zeros([size, sequence_leng, input_dim], dtype=torch.float32)\n",
    "Y = torch.zeros([size, sequence_leng, output_dim], dtype=torch.float32)\n",
    "network = []\n",
    "for i in tqdm(range(size)) :\n",
    "    file_name = f\"Output/5by5_Data{i}\"\n",
    "    x, y = generate_xy(file_name, path_encoded)\n",
    "    X[i] = x \n",
    "    Y[i] = y \n",
    "\n",
    "    # file = open(file_name, \"rb\")\n",
    "    # stat = pickle.load(file)\n",
    "    # file.close()\n",
    "    # path_links = stat[\"path_flow\"]\n",
    "    # nodes = stat[\"data\"][\"nodes\"]\n",
    "    # Path_tensor = normalize_tensor(preprocess_path(path_links, nodes, path_encoded))\n",
    "    # network.append(Path_tensor)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([30, 625, 1164])\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish encoder\n",
      "Encoder output shape:  torch.Size([30, 625, 2048])\n"
     ]
    }
   ],
   "source": [
    "%run attention.py\n",
    "\n",
    "# X = torch.flatten(X, start_dim=1)\n",
    "print(\"input shape: \", X.shape)\n",
    "\n",
    "x2 = Encoder(input_dim=input_dim, d_model=2048, N=2, heads=8, dropout=0.1)(X)\n",
    "print(\"Encoder output shape: \", x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 625, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run attention.py\n",
    "decoder = Decoder(output_dim, 2048, 2, 8, 0.1)\n",
    "x3 = decoder(Y, x2)\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish encoder\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 625, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run attention.py\n",
    "\n",
    "transformer = Transformer(input_dim=input_dim, output_dim=output_dim, d_model=512, N=2,heads=8, dropout=0.1)\n",
    "out = transformer(X, Y)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073931</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>0.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.140311</td>\n",
       "      <td>-0.873479</td>\n",
       "      <td>0.172980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.150692</td>\n",
       "      <td>-0.885234</td>\n",
       "      <td>0.166668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147159</td>\n",
       "      <td>-0.879593</td>\n",
       "      <td>0.169880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.088899</td>\n",
       "      <td>0.485946</td>\n",
       "      <td>0.074822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.073931  1.032052  0.251043\n",
       "1 -0.140311 -0.873479  0.172980\n",
       "2 -0.150692 -0.885234  0.166668\n",
       "3 -0.147159 -0.879593  0.169880\n",
       "4 -0.088899  0.485946  0.074822"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out[0].detach().numpy())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY TRAINING AND VALIDATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(input_dim=input_dim, output_dim=output_dim, d_model=512, N=2,heads=8, dropout=0.1)\n",
    "epochs = 100\n",
    "\n",
    "model.to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in train_data_loader:\n",
    "        # Move the batch to the device\n",
    "        src, trg = batch\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, trg[:, :-1])\n",
    "        output = output.reshape(-1, output.size(-1))\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        # Compute the loss and backpropagate\n",
    "        loss = criterion(output, trg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_data_loader:\n",
    "            # Move the batch to the device\n",
    "            src, trg = batch\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(output, trg)\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    # Print the training and validation losses\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {total_train_loss/len(train_data_loader):.4f}, Val Loss: {total_val_loss/len(val_data_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
