{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD SOLUTION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from attention import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract OD demand and path set (X and Y)\n",
    "X: OD demand, graph (link feature), path, link-path adj \\\n",
    "Y: path flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py\n",
    "%run attention.py\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, size, input_dim0, input_dim1, output_dim0, output_dim1, start_from=0):\n",
    "        super().__init__()\n",
    "        self.path_encoded = path_encoder() # Get path encode dictionary\n",
    "        self.entries = size\n",
    "        self.X = torch.zeros([size, input_dim0, input_dim1], dtype=torch.float32)\n",
    "        self.Y = torch.zeros([size, output_dim0, output_dim1], dtype=torch.float32)\n",
    "\n",
    "        for i in tqdm(range(size)) :\n",
    "            file_name = f\"Output/5by5_Data{start_from+i}\"\n",
    "            x, y = generate_xy(file_name, self.path_encoded)\n",
    "            self.X[i] = x\n",
    "            self.Y[i] = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.entries\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.X[idx]\n",
    "        data_label = self.Y[idx]\n",
    "        return data_point, data_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run helpers.py\n",
    "\n",
    "# Load first 1000 sample data\n",
    "train_size = 10\n",
    "train_dataset = Dataset(train_size, 625, 1165, 625, 3)\n",
    "# this code create batch data, shape batch_size x seq_length x dim\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85c75f449734ca78b76a4851e64d70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(torch.cuda.is_available())\n",
    "%run helpers.py\n",
    "\n",
    "size = 30\n",
    "sequence_leng = 625\n",
    "input_dim = 1164\n",
    "output_dim = 3\n",
    "path_encoded = path_encoder()\n",
    "\n",
    "X = torch.zeros([size, sequence_leng, input_dim], dtype=torch.float32)\n",
    "Y = torch.zeros([size, sequence_leng, output_dim], dtype=torch.float32)\n",
    "network = []\n",
    "for i in tqdm(range(size)) :\n",
    "    file_name = f\"Output/5by5_Data{i}\"\n",
    "    x, y = generate_xy(file_name, path_encoded)\n",
    "    X[i] = x \n",
    "    Y[i] = y \n",
    "\n",
    "    # file = open(file_name, \"rb\")\n",
    "    # stat = pickle.load(file)\n",
    "    # file.close()\n",
    "    # net = stat[\"data\"][\"network\"]\n",
    "    # Graph = normalize_tensor(get_graphTensor(net))\n",
    "    # Graph = get_graphTensor(net)\n",
    "    # network.append(Graph)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([30, 625, 1164])\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish encoder\n",
      "Encoder output shape:  torch.Size([30, 625, 2048])\n"
     ]
    }
   ],
   "source": [
    "%run attention.py\n",
    "\n",
    "# X = torch.flatten(X, start_dim=1)\n",
    "print(\"input shape: \", X.shape)\n",
    "\n",
    "x2 = Encoder(input_dim=input_dim, d_model=2048, N=2, heads=8, dropout=0.1)(X)\n",
    "print(\"Encoder output shape: \", x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2   3   4   5\n",
       "0  0.000000  0.000000  0.041667 NaN NaN NaN\n",
       "1  0.012658  0.041667  0.000000 NaN NaN NaN\n",
       "2  0.025316  0.000000  0.208333 NaN NaN NaN\n",
       "3  0.037975  0.208333  0.000000 NaN NaN NaN\n",
       "4  0.050633  0.041667  0.083333 NaN NaN NaN\n",
       "5  0.063291  0.083333  0.041667 NaN NaN NaN\n",
       "6  0.075949  0.041667  0.250000 NaN NaN NaN\n",
       "7  0.088608  0.250000  0.041667 NaN NaN NaN\n",
       "8  0.101266  0.083333  0.125000 NaN NaN NaN\n",
       "9  0.113924  0.125000  0.083333 NaN NaN NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X[0].numpy())\n",
    "df.iloc[:10, :6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 625, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run attention.py\n",
    "decoder = Decoder(output_dim, 2048, 2, 8, 0.1)\n",
    "x3 = decoder(Y, x2)\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish encoder\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n",
      "Finish calculate attention score\n",
      "Finish Multihead attention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([625, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run attention.py\n",
    "\n",
    "transformer = Transformer(input_dim=input_dim, output_dim=output_dim, d_model=2048, N=2,heads=8, dropout=0.1)\n",
    "out = transformer(X, Y)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.497437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0 -0.497437\n",
       "1  0.029807\n",
       "2  0.186898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out[0].detach().numpy())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
